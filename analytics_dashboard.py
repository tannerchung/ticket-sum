"""
Advanced Analytics Dashboard Components
Provides sophisticated visualization components for the enhanced analytics system.
"""

import streamlit as st
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import pandas as pd
import numpy as np
from datetime import datetime, timedelta
from typing import Dict, List, Any

from advanced_analytics import (
    ProductionObservabilityPlatform, 
    EnhancedCollaborationAnalytics,
    CostQualityOptimizationAnalytics,
    get_comprehensive_analytics_report
)


def display_collaboration_intelligence_dashboard():
    """Display advanced collaboration intelligence metrics"""
    st.markdown("## üß† Collaboration Intelligence Analytics")
    st.markdown("*Advanced metrics measuring authentic multi-agent collaboration quality*")
    
    # Time window selector
    col1, col2 = st.columns([1, 3])
    with col1:
        time_window = st.selectbox(
            "Analysis Period",
            [1, 6, 24, 72, 168],  # hours
            index=2,
            format_func=lambda x: f"Last {x} hours" if x < 24 else f"Last {x//24} days"
        )
    
    # Get analytics data
    with st.spinner("Analyzing collaboration patterns..."):
        platform = ProductionObservabilityPlatform()
        metrics = platform.generate_real_time_metrics_dashboard(time_window)
        collaboration_metrics = metrics.get('collaboration_intelligence', {})
    
    # Key metrics cards
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        consensus_quality = collaboration_metrics.get('avg_consensus_quality', 0.0)
        st.metric(
            "Consensus Quality",
            f"{consensus_quality:.2f}",
            delta=f"{(consensus_quality - 0.75):.2f}" if consensus_quality > 0 else None,
            help="Quality of consensus reached between agents (0-1)"
        )
    
    with col2:
        disagreement_rate = collaboration_metrics.get('disagreement_rate', 0.0)
        st.metric(
            "Authentic Disagreement Rate",
            f"{disagreement_rate:.1f}",
            delta=f"{(disagreement_rate - 2.0):.1f}" if disagreement_rate > 0 else None,
            help="Rate of authentic disagreements per collaboration session"
        )
    
    with col3:
        resolution_efficiency = collaboration_metrics.get('resolution_efficiency', 0.0)
        st.metric(
            "Resolution Efficiency",
            f"{resolution_efficiency:.3f}",
            delta=f"{(resolution_efficiency - 0.1):.3f}" if resolution_efficiency > 0 else None,
            help="Efficiency of disagreement resolution (higher = faster resolution)"
        )
    
    with col4:
        collaboration_sessions = collaboration_metrics.get('collaboration_sessions', 0)
        st.metric(
            "Active Collaborations",
            f"{collaboration_sessions}",
            help="Number of collaboration sessions in time window"
        )
    
    # Collaboration quality over time
    st.markdown("### üìà Collaboration Quality Trends")
    
    if collaboration_sessions > 0:
        # Create sample time series data for demonstration
        hours = list(range(time_window))
        quality_trend = [0.7 + 0.1 * np.sin(h/4) + np.random.normal(0, 0.05) for h in hours]
        authenticity_trend = [0.6 + 0.15 * np.cos(h/6) + np.random.normal(0, 0.04) for h in hours]
        
        fig = make_subplots(
            rows=2, cols=1,
            subplot_titles=('Consensus Quality Over Time', 'Disagreement Authenticity Score'),
            vertical_spacing=0.1
        )
        
        fig.add_trace(
            go.Scatter(
                x=hours,
                y=quality_trend,
                mode='lines+markers',
                name='Consensus Quality',
                line=dict(color='#1f77b4', width=2),
                hovertemplate='Hour: %{x}<br>Quality: %{y:.3f}<extra></extra>'
            ),
            row=1, col=1
        )
        
        fig.add_trace(
            go.Scatter(
                x=hours,
                y=authenticity_trend,
                mode='lines+markers',
                name='Authenticity Score',
                line=dict(color='#ff7f0e', width=2),
                hovertemplate='Hour: %{x}<br>Authenticity: %{y:.3f}<extra></extra>'
            ),
            row=2, col=1
        )
        
        fig.update_layout(
            height=500,
            showlegend=False,
            title_text="Collaboration Intelligence Trends"
        )
        fig.update_yaxes(range=[0, 1])
        
        st.plotly_chart(fig, use_container_width=True)
    else:
        st.info("No collaboration data available for the selected time period.")
    
    # Agent influence network
    st.markdown("### üï∏Ô∏è Agent Influence Network")
    
    col1, col2 = st.columns([2, 1])
    
    with col1:
        # Create agent influence network visualization
        agents = ['Triage Specialist', 'Ticket Analyst', 'Support Strategist', 'QA Reviewer']
        
        # Sample influence data
        influence_data = {
            'source': ['Triage Specialist', 'Ticket Analyst', 'Support Strategist', 'Triage Specialist', 'QA Reviewer'],
            'target': ['Ticket Analyst', 'Support Strategist', 'QA Reviewer', 'Support Strategist', 'Ticket Analyst'],
            'influence_strength': [0.8, 0.7, 0.9, 0.6, 0.5]
        }
        
        # Create network graph (simplified visualization)
        fig = go.Figure()
        
        # Add nodes
        node_x = [0, 1, 1, 0]
        node_y = [0, 0, 1, 1]
        
        fig.add_trace(go.Scatter(
            x=node_x, y=node_y,
            mode='markers+text',
            marker=dict(size=50, color='lightblue'),
            text=agents,
            textposition="middle center",
            hovertemplate='%{text}<extra></extra>',
            name='Agents'
        ))
        
        # Add edges (simplified)
        for i, (source, target, strength) in enumerate(zip(influence_data['source'], influence_data['target'], influence_data['influence_strength'])):
            source_idx = agents.index(source)
            target_idx = agents.index(target)
            
            fig.add_trace(go.Scatter(
                x=[node_x[source_idx], node_x[target_idx]],
                y=[node_y[source_idx], node_y[target_idx]],
                mode='lines',
                line=dict(width=strength*5, color=f'rgba(255,0,0,{strength})'),
                hovertemplate=f'{source} ‚Üí {target}<br>Influence: {strength:.2f}<extra></extra>',
                showlegend=False
            ))
        
        fig.update_layout(
            title="Agent Influence Network",
            showlegend=False,
            xaxis=dict(showgrid=False, zeroline=False, showticklabels=False),
            yaxis=dict(showgrid=False, zeroline=False, showticklabels=False),
            height=400
        )
        
        st.plotly_chart(fig, use_container_width=True)
    
    with col2:
        st.markdown("**Influence Metrics:**")
        
        influence_scores = {
            'QA Reviewer': 0.89,
            'Support Strategist': 0.76,
            'Ticket Analyst': 0.68,
            'Triage Specialist': 0.54
        }
        
        for agent, score in influence_scores.items():
            st.metric(
                agent.split()[0],  # Shortened name
                f"{score:.2f}",
                help=f"How much {agent} influences other agents' decisions"
            )


def display_cost_optimization_dashboard():
    """Display cost-quality optimization analytics"""
    st.markdown("## üí∞ Cost-Quality Optimization Analytics")
    st.markdown("*Intelligent cost optimization with quality preservation*")
    
    # Initialize analytics
    cost_analytics = CostQualityOptimizationAnalytics()
    
    # Cost efficiency overview
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.metric(
            "Cost per Quality Point",
            "$0.023",
            delta="-$0.005",
            delta_color="inverse",
            help="Average cost to achieve one quality point"
        )
    
    with col2:
        st.metric(
            "Model Efficiency Score",
            "8.7/10",
            delta="+0.3",
            help="Overall model selection efficiency"
        )
    
    with col3:
        st.metric(
            "Optimization Opportunities",
            "3",
            help="Number of identified optimization opportunities"
        )
    
    with col4:
        st.metric(
            "Predicted Monthly Savings",
            "$247",
            delta="+$52",
            help="Estimated cost savings from optimizations"
        )
    
    # Model efficiency comparison
    st.markdown("### ü§ñ Model Efficiency Analysis")
    
    col1, col2 = st.columns([2, 1])
    
    with col1:
        # Sample model efficiency data
        model_data = {
            'Model': ['GPT-4o', 'GPT-4o Mini', 'Claude-3.5 Sonnet', 'Claude-3.5 Haiku', 'Command-R Plus'],
            'Quality Score': [0.89, 0.76, 0.91, 0.68, 0.73],
            'Cost per 1K Tokens': [0.02, 0.0008, 0.018, 0.0015, 0.018],
            'Efficiency Score': [8.5, 9.2, 8.8, 7.1, 6.9]
        }
        
        df = pd.DataFrame(model_data)
        
        # Create efficiency scatter plot
        fig = px.scatter(
            df, 
            x='Cost per 1K Tokens', 
            y='Quality Score',
            size='Efficiency Score',
            color='Efficiency Score',
            hover_name='Model',
            title="Model Cost vs Quality Analysis",
            labels={
                'Cost per 1K Tokens': 'Cost per 1K Tokens ($)',
                'Quality Score': 'Average Quality Score'
            }
        )
        
        fig.update_layout(height=400)
        st.plotly_chart(fig, use_container_width=True)
    
    with col2:
        st.markdown("**Model Rankings:**")
        
        # Sort by efficiency score
        sorted_models = df.sort_values('Efficiency Score', ascending=False)
        
        for i, (_, row) in enumerate(sorted_models.iterrows()):
            rank_color = "ü•á" if i == 0 else "ü•à" if i == 1 else "ü•â" if i == 2 else "üìä"
            st.write(f"{rank_color} **{row['Model']}**")
            st.write(f"   Efficiency: {row['Efficiency Score']:.1f}/10")
            st.write(f"   Quality: {row['Quality Score']:.2f}")
            st.write("")
    
    # Complexity-based routing analysis
    st.markdown("### üéØ Complexity-Based Routing Performance")
    
    col1, col2 = st.columns(2)
    
    with col1:
        # Complexity distribution
        complexity_data = {
            'Complexity Level': ['Low', 'Medium', 'High', 'Very High'],
            'Ticket Count': [45, 32, 18, 5],
            'Optimal Model Hit Rate': [0.92, 0.85, 0.78, 0.71]
        }
        
        fig = make_subplots(specs=[[{"secondary_y": True}]])
        
        fig.add_trace(
            go.Bar(
                name='Ticket Count',
                x=complexity_data['Complexity Level'],
                y=complexity_data['Ticket Count'],
                marker_color='lightblue'
            ),
            secondary_y=False,
        )
        
        fig.add_trace(
            go.Scatter(
                name='Hit Rate',
                x=complexity_data['Complexity Level'],
                y=complexity_data['Optimal Model Hit Rate'],
                mode='lines+markers',
                marker_color='red',
                line=dict(width=3)
            ),
            secondary_y=True,
        )
        
        fig.update_xaxes(title_text="Ticket Complexity Level")
        fig.update_yaxes(title_text="Number of Tickets", secondary_y=False)
        fig.update_yaxes(title_text="Model Selection Hit Rate", secondary_y=True)
        fig.update_layout(title_text="Complexity Distribution & Routing Performance")
        
        st.plotly_chart(fig, use_container_width=True)
    
    with col2:
        # Optimization opportunities
        st.markdown("**üéØ Optimization Opportunities:**")
        
        opportunities = [
            {
                'type': 'Model Substitution',
                'description': 'Replace GPT-4o with Claude-3.5 Sonnet for technical tickets',
                'potential_savings': '$89/month',
                'confidence': 'High'
            },
            {
                'type': 'Complexity Routing',
                'description': 'Improve low-complexity ticket detection',
                'potential_savings': '$56/month',
                'confidence': 'Medium'
            },
            {
                'type': 'Batch Processing',
                'description': 'Group similar tickets for efficiency',
                'potential_savings': '$42/month',
                'confidence': 'High'
            }
        ]
        
        for opp in opportunities:
            with st.expander(f"üí° {opp['type']} - {opp['potential_savings']}"):
                st.write(f"**Description:** {opp['description']}")
                st.write(f"**Confidence:** {opp['confidence']}")
                st.write(f"**Estimated Savings:** {opp['potential_savings']}")
                if st.button(f"Implement {opp['type']}", key=f"impl_{opp['type']}"):
                    st.success("Optimization queued for implementation!")


def display_production_observability_dashboard():
    """Display production-grade observability metrics"""
    st.markdown("## üöÄ Production Observability Platform")
    st.markdown("*Enterprise-grade monitoring and alerting for multi-agent systems*")
    
    # Get comprehensive analytics report
    with st.spinner("Loading production metrics..."):
        report = get_comprehensive_analytics_report(24)
    
    metrics = report['metrics']
    anomalies = report['anomalies']
    
    # System health overview
    st.markdown("### üè• System Health Overview")
    
    col1, col2, col3, col4, col5 = st.columns(5)
    
    with col1:
        processing_volume = metrics.get('processing_volume', {})
        st.metric(
            "Tickets/Hour",
            f"{processing_volume.get('tickets_per_hour', 0):.1f}",
            help="Processing throughput"
        )
    
    with col2:
        completion_rate = processing_volume.get('completion_rate', 0)
        st.metric(
            "Completion Rate",
            f"{completion_rate:.1%}",
            delta=f"{(completion_rate - 0.95):.1%}" if completion_rate > 0 else None,
            help="Percentage of successfully completed tickets"
        )
    
    with col3:
        system_health = metrics.get('system_health', {})
        error_rate = system_health.get('error_rate', 0)
        st.metric(
            "Error Rate",
            f"{error_rate:.1%}",
            delta=f"{(error_rate - 0.02):.1%}" if error_rate > 0 else None,
            delta_color="inverse",
            help="System error rate"
        )
    
    with col4:
        avg_processing_time = system_health.get('avg_processing_time', 0)
        st.metric(
            "Avg Processing Time",
            f"{avg_processing_time:.0f}s",
            delta=f"{(avg_processing_time - 45):.0f}s" if avg_processing_time > 0 else None,
            delta_color="inverse",
            help="Average ticket processing time"
        )
    
    with col5:
        active_sessions = system_health.get('active_sessions', 0)
        st.metric(
            "Active Sessions",
            f"{active_sessions}",
            help="Number of active processing sessions"
        )
    
    # Alerts and anomalies
    st.markdown("### üö® Alerts & Anomalies")
    
    if anomalies:
        for anomaly in anomalies:
            severity = anomaly.get('severity', 'info')
            emoji = "üî¥" if severity == 'critical' else "üü°" if severity == 'warning' else "üîµ"
            
            with st.expander(f"{emoji} {anomaly.get('type', 'Unknown').replace('_', ' ').title()} - {severity.upper()}"):
                st.write(f"**Message:** {anomaly.get('message', 'No details available')}")
                st.write(f"**Recommendation:** {anomaly.get('recommendation', 'No recommendation available')}")
                
                col1, col2 = st.columns(2)
                with col1:
                    if st.button("Acknowledge", key=f"ack_{anomaly.get('type')}"):
                        st.success("Alert acknowledged!")
                
                with col2:
                    if st.button("Auto-Resolve", key=f"resolve_{anomaly.get('type')}"):
                        st.success("Auto-resolution initiated!")
    else:
        st.success("üü¢ No anomalies detected - system running normally")
    
    # Performance trends
    st.markdown("### üìä Performance Trends")
    
    col1, col2 = st.columns(2)
    
    with col1:
        # Processing volume trend
        hours = list(range(24))
        volume_trend = [5 + 3 * np.sin(h/4) + np.random.normal(0, 0.5) for h in hours]
        
        fig = go.Figure()
        fig.add_trace(go.Scatter(
            x=hours,
            y=volume_trend,
            mode='lines+markers',
            name='Tickets/Hour',
            line=dict(color='#1f77b4', width=2),
            fill='tonexty'
        ))
        
        fig.update_layout(
            title="Processing Volume (24h)",
            xaxis_title="Hours Ago",
            yaxis_title="Tickets per Hour",
            height=300
        )
        
        st.plotly_chart(fig, use_container_width=True)
    
    with col2:
        # Quality trend
        quality_trend = [0.85 + 0.05 * np.cos(h/6) + np.random.normal(0, 0.02) for h in hours]
        
        fig = go.Figure()
        fig.add_trace(go.Scatter(
            x=hours,
            y=quality_trend,
            mode='lines+markers',
            name='Quality Score',
            line=dict(color='#2ca02c', width=2),
            fill='tonexty'
        ))
        
        fig.update_layout(
            title="Quality Score Trend (24h)",
            xaxis_title="Hours Ago",
            yaxis_title="Average Quality Score",
            yaxis=dict(range=[0.7, 1.0]),
            height=300
        )
        
        st.plotly_chart(fig, use_container_width=True)
    
    # Key insights
    st.markdown("### üîç AI-Generated Insights")
    
    insights = report.get('summary', {}).get('key_insights', [])
    
    if insights:
        for insight in insights:
            st.info(f"üí° {insight}")
    else:
        st.info("üí° System operating within normal parameters")
    
    # Export options
    st.markdown("### üì§ Export & Integration")
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        if st.button("üìä Export Metrics"):
            st.download_button(
                label="Download JSON Report",
                data=json.dumps(report, indent=2),
                file_name=f"analytics_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json",
                mime="application/json"
            )
    
    with col2:
        if st.button("üîî Configure Alerts"):
            st.info("Alert configuration panel would open here")
    
    with col3:
        if st.button("üîß Auto-Optimize"):
            st.info("Automatic optimization routines would be triggered here")


def display_enhanced_analytics_overview():
    """Main enhanced analytics dashboard"""
    st.set_page_config(
        page_title="Advanced Analytics Platform",
        page_icon="üß†",
        layout="wide"
    )
    
    st.markdown("# üß† Advanced Multi-Agent Analytics Platform")
    st.markdown("*Sophisticated intelligence for collaborative AI systems*")
    
    # Navigation tabs
    tab1, tab2, tab3 = st.tabs([
        "üß† Collaboration Intelligence",
        "üí∞ Cost Optimization", 
        "üöÄ Production Observability"
    ])
    
    with tab1:
        display_collaboration_intelligence_dashboard()
    
    with tab2:
        display_cost_optimization_dashboard()
    
    with tab3:
        display_production_observability_dashboard()


if __name__ == "__main__":
    display_enhanced_analytics_overview()